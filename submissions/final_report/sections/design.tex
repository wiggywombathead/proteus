\section{Design}

\subsection{Hardware}
    The project has been developed for the Raspberry Pi 1 Model B+.
    Some of the relevant hardware onboard includes:
    \begin{itemize}
        \itemsep0em
        \item System-on-Chip: Broadcom BCM2835
        \item CPU: 700MHZ ARM1176JZF-S
        \item GPU: 250MHz Broadcom VideoCore IV
        \item SDRAM: 512MiB, shared with the GPU
        \item Video output: HDMI and DSI
        \item Storage: MicroSDHC slot
        \item 4x USB 2.0 ports
        \item 40 General Purpose Input/Output (GPIO) pins
    \end{itemize}

    \begin{figure}[h]
        \centering
        \includegraphics[width=.8\textwidth]{board.png}
        \caption{Raspberry Pi 1 Model B+}
    \end{figure}

    Development was initially planned for the Raspberry Pi 2 Model B+ simply due
    to its availability, having been received as a gift some years prior.
    However, focus was switched to target the Raspberry Pi 1 Model B+ as a
    result of the difficulties encountered with interacting with the GPU via the
    mailbox interface, with the processing differing slightly and being more
    complex on the 2. The underlying architecture of the 1's BCM2835 chip is,
    however, identical to that of the BCM2836 and BCM2837
    \cite{IdenticalArchitecture}, used by the Raspberry Pi 2 and 3,
    respectively. They only differ in that the 1 uses the ARM1176JZF-S
    processor, as opposed to the quad-core Cortex-A7 and quad-core Cortex-A53
    cluster used by these later boards, in addition to the 512MiB extra
    available to them. Therefore, the choice between specific models for which
    to develop would have made little difference to the outcome of the project,
    and indeed much of the code is transferable. As has been discussed, this
    standard set of hardware was desirable for the project's aims, rendering the
    operating system more widely accessible and for less effort.

    \subsubsection{The Raspberry Pi's boot process}
        \label{sec:booting}
        The decision to work with the Raspberry Pi in particular, as opposed to
        a more open-ended PC setup, is not only due to the relative lack of
        material available for operating systems development on the ARM
        architecture, but also as a result of the much simpler boot process in
        contrast to other hardware, details of which were found from
        \cite{BootProcess}. Booting is handled almost entirely by the Pi's
        system-on-chip, thus does not require the writing of a custom
        bootloader. Instead, it relies on closed-source proprietary firmware
        programmed into the SoC processor which may not be modified. The
        necessary files can be acquired by either downloading them from
        \cite{Firmware}, or by downloading an existing operating system for the
        Pi and using the files that it provides (since it still requires the
        same firmware).

        During system boot, the ARM CPU does not act as the main CPU, but rather
        as a coprocessor to the VideoCore GPU \cite{PiHackability}. When the
        system is first powered on, the ARM CPU is halted and SDRAM is disabled.
        Control is passed to the GPU, whose responsibility it is to execute the
        bootloader. The bootloader itself is divided into three stages: the
        first stage, stored in ROM on the system-on-chip; the second stage,
        \code{bootcode.bin}, and the third stage, \code{start.elf}. The first
        mounts the FAT32 boot partition on the SD card to enable execution of
        the second-stage bootloader, and then loads this into the L2 cache to
        run it. Control is then passed to the second-stage bootloader, which
        enables SDRAM and loads \code{start.elf} for execution. This final stage
        allows the GPU to start up the CPU. An additional file,
        \code{fixup.dat}, is used to configure the shared SDRAM partition
        between the two processors. The GPU firmware reads the files
        \code{config.txt} and \code{cmdline.txt} to load the kernel image, then
        releases the CPU from reset and transfers control to it to begin
        executing the kernel. 

        After an operating system is loaded, the code on the GPU is not
        unloaded, but rather runs its own simple operating system, the VideoCore
        Operating System (VCOS) \cite{VideoCore}. This can be used to
        communicate with the services provided by the GPU (for example,
        providing a framebuffer), using the mailbox peripheral and ARM CPU
        interrupts, which the GPU is capable of producing. The GPU is not only
        in charge of graphical functions as, for example, it also controls the
        system timer and audio -- in this way it is therefore more akin to a
        regular PC's BIOS.

\subsection{Resources \& Environment}
    The project was developed on various x86 machines running the Linux kernel
    version 4.16 onwards. Since the target environment, the Raspberry Pi 1 Model
    B+, runs on an ARM CPU, the target architecture is therefore different to
    that of the development machines. Therefore, a cross-compiler is required in
    order to compile the code for the target machine. Available on the ARM
    developer website is the GNU Embedded Toolchain \cite{GNUToolchain}.
    Conveniently, this suite of tools is available from Arch Linux's package
    manager, Pacman \cite{PacmanEABI}, and this is the version that has been
    used to develop the project.

    \subsubsection{Technical Documentation}
        With no prior experience working in assembly and, in particular, how to
        use ARM assembly in conjunction with the C programming language, it was
        necessary to become better acquainted with this environment, including
        becoming familiar with the instructions available and the calling
        conventions that must be followed (for example, returning the result of
        an assembly procedure call in register 0). This information was gathered
        by reading through both official and unofficial documentation on the ARM
        environment in general and the specifics of working with the Pi. In
        particular, the following were the main resources of technical
        documentation used throughout the project:
        \begin{itemize}
            \itemsep0em 
            \item \textit{ARM Architecture Reference Manual} \cite{ARMARM}
            \item \textit{ARM1176JZF-S Technical Reference Manual} \cite{TRM}
            \item \textit{ARM Developer Suite Assembler Guide}
                \cite{OnlineARMGuide}
            \item \textit{ARM Cortex-A Series: Programmer's Guide}
                \cite{ProgrammersGuide}
            \item \textit{Broadcom BCM2835 ARM Peripherals Manual} \cite{BCM2835}
        \end{itemize}

        The technical and architecture reference manuals provide in-depth
        information for such concepts as the programmer's model or interaction
        with different pieces of hardware on board the Pi. They also include
        architectural information regarding the Pi's three standard coprocessor
        extensions: the system control processor (coprocessor 15), the Vector
        Floating-Point unit (coprocessors 10 and 11), and the debug architecture
        interface (coprocessor 14).  The online guide at \cite{OnlineARMGuide}
        provides comprehensive coverage of the instructions to use when using
        assembly to program on the ARM CPU, and used in conjunction with the
        programmer's guide provides an understanding of when and how to use
        certain instructions.  Although not written for the processor used by
        the Raspberry Pi 1, instead written for the CPU used by the 2 and 3, the
        programmer's guide provided further examples of various instructions'
        use-cases, and its utility continued even when focus shifted from the
        Raspberry Pi 2 to the Raspberry Pi 1.

        On the Raspberry Pi are various peripherals, such as the Universal
        Asynchronous Receiver/Transmitter (UART), system and ARM timers, or the
        interrupt controller. Information regarding the layout of their
        registers and the memory addresses from and to which to read and write
        was obtained from the peripherals manual. Since the underlying
        architecture behind the BCM2835 and BCM2836/7 is largely the same, the
        manual was helpful both in development for the Raspberry 1 and 2, with
        the BCM2836 \cite{BCM2836} providing some extra processor specifics in
        the case of the latter.

    \subsubsection{System V ABI}
        Of particular use within GNU's suite of tools is the cross-compiler for
        \code{arm-none-eabi}, which provides a toolchain to target the System V
        ABI (Application Binary Interface). This is a set of specifications that
        detail the calling conventions, object and executable file formats,
        dynamic linking semantics, and more, for systems complying with the
        System V Interface Definition, of which the Raspberry Pi is one. For
        example, it defines the Executable and Linkable Format, or ELF, which is
        a format for storing programs or fragments of programs on disk that are
        generated as a result of compiling and linking. Each ELF file is divided
        into sections, specifically:
        \begin{itemize}
            \label{list:LinkerSections}
            \itemsep0em
            \item \code{.text} - executable code
            \item \code{.data} - global variables which are uninitialised at
                compile-time
            \item \code{.rodata} - read-only data i.e. global constants
            \item \code{.bss} - uninitialised global variables
        \end{itemize}

        These are covered in more depth in the discussion of the linking process
        in section \ref{sec:Linker}. Additionally the SysV ABI defines the
        \code{.comment}, \code{.note}, \code{.stab}, and \code{.stabstr}
        sections for compiler and linker toolchain comments and debugging
        information.

    \subsubsection{ARM environment}
        \label{sec:ARMenv}
        The ARM1176JZF-S processor implements the ARM11 ARMv6 architecture
        \cite{TRM}, supporting both the ARM and Thumb instruction sets\footnote{A
        subset of the most commonly-used 32-bit ARM instructions.  Each Thumb
        instruction is 16 bits long, and has a corresponding 32-bit ARM
        instruction with an equivalent effect on the processor model. While not
        useful and out-of-scope for this project, the instruction sets can be
        easily switched between to enable the programmer to optimize for either
        performance or code density as they see fit.}. The processor contains 33
        general-purpose 32-bit registers and 7 dedicated 32-bit registers, 16 of
        which are accessible for general use at any one time in the ARM state.
        These are as follows:
        \begin{itemize}
            \itemsep0em
            \item \code{r15} - Program Counter
            \item \code{r14} - Link Register
            \item \code{r13} - Stack Pointer
            \item \code{r12} - Intra-Procedure-Call Scratch Register
            \item \code{r4-r11} - local variables to a function
            \item \code{r0-r3} - arguments passed to a function, and the returned
                result
        \end{itemize}

        The Current Program Status Register (CPSR) contains code flags, status
        bits, and current mode bits.  Another register, the Saved Program Status
        Register (SPSR), is similar to the CPSR but is only available in
        privileged modes (see Section \ref{sec:CPU_modes}. This contains the
        condition code flags, status bits, and current mode bits saved as a
        result of the exception which prompted the processor to enter the
        current mode.

        The architecture asserts a full descending stack: full, meaning the
        stack pointer points to the topmost entry in the
        stack\footnote{Contrasted to empty, which points to the next free
        location, i.e. the address at which the next item will be stored.}; and
        descending, meaning the stack grows downwards, starting from a high
        memory address and progressing to lower addresses as items are pushed.

        As a final note on correctly interacting with the ARM environment, any
        procedure calls must preserve the contents of registers 4 to 11 and the
        stack pointer. Further, subroutines calling other subroutines must save
        the return address (found in the link register) to the stack before
        calling that subroutine.

    \subsubsection{Tools}
        The following is a summary of the tools used to develop the project:
        \begin{table}[h]
            \centering
            \begin{tabular}{|l|l|}
                \hline			
                \textbf{Languages} & C, ARM assembly \\ \hline
                \textbf{Cross-compiler toolchain} & GNU Embedded Toolchain
                (\code{arm-none-eabi-*}) \\ \hline
                \textbf{Build automation} & GNU Make \\ \hline
                \textbf{Version control} & Git, hosted remotely on Github \\ \hline
                \textbf{Emulation} & QEMU \\ \hline
                \textbf{Documentation} & Doxygen \\ \hline
            \end{tabular}

            \caption{Tools used by the project}
        \end{table}

        The project uses the C language both due to its familiarity as well as
        its ease-of-setup on the embedded environment, however there are times
        in such an environment, and especially for operating systems
        development, that assembly is more suitable \cite{InappropriateC}, and
        was thus opted for instead. As already discussed, the GNU Embedded
        Toolchain has been used to target the ARM architecture for which the
        project is built.

        The GNU Embedded Toolchain consists of several utilities, all of which
        are used at various stages in the project's development:
        \code{arm-none-eabi-gcc} is responsible for compiling the C and ARM
        assembly files into object files; \code{arm-none-eabi-ld} is an embedded
        platform-independent linker, used to link multiple object files into a
        single \code{.elf} file; \code{arm-none-eabi-objcopy} converts the
        resultant \code{.elf} file into a binary (system executable, or
        \code{.img}) file; \code{arm-none-eabi-objdump} provides helpful
        debugging information about the final executable file (for example, used
        as a disassembler it presents the kernel image in assembly form); and
        \code{arm-none-eabi-gdb} provides the familiar interface of the GNU
        debugger.

        As the project increased in complexity, especially with the addition of
        multiple source files, GNU's Make utility was used to automate the build
        process. This involved becoming familiar with concepts regarding rules,
        with GNU's online manual page \cite{MakeManual} and \cite{MakeVariables}
        being of particular help.

        Throughout its early stages, the project operated solely in an emulated
        environment, simply as it provided quicker feedback with respect to
        testing, which is already limited and slow in such an environment.
        For this purpose QEMU was consequently used. However, due to its lack of
        simulation of a system timer, an important aspect when programming
        interrupts and process scheduling, focus had to eventually be shifted
        towards operating on real hardware, limiting QEMU's influence on the
        project as a whole.
 
\subsection{System Overview}
    The project presents an operating which is capable of booting on a Raspberry
    Pi 1 Model B+ and running (with reduced functionality) on an environment
    emulating the Raspberry Pi 2 Model B, and initialises a C runtime
    environment. It provides a mechanism for memory management, first in the
    form of determining the total memory available to the system, and then in
    dividing this up into 4kiB pages. A dynamic memory allocator is set up in
    the form of a 1MiB portion of ``heap'' memory, and provides an interface
    similar to the C standard library's \code{malloc()} and \code{free()} in
    order to manage this.

    Visual feedback is provided in the form of output to HDMI and, in the
    virtual environment, output to serial via the UART peripheral.  The
    mechanism for communication with the GPU is set up and managed using the
    mailbox peripheral, and output via HDMI is achieved by requesting and
    providing relevant data (dimensions, bits per pixel, etc.) to the
    framebuffer. User interaction is so far only achieved in the virtual
    environment, again doing so via UART, with real-world interaction via USB
    proving to be a significant source of challenge throughout development.

    The project sets up interrupts and exceptions by providing various exception
    handlers. This is with the main aim of interacting with the system timer, a
    peripheral capable of generating interrupts every set amount of time, for
    use in process scheduling. It also provides a somewhat intuitive interface
    for registering new ``types'' of interrupts (further covered in Section
    \ref{sec:IRQs}). Processes are implemented and stored using the standard
    job- and ready-queues, and a simple interface for creating new threads of
    execution is provided.

    With process scheduling being one of the main systems designed for ease of
    understanding and extensibility, the project provides a simple interface for
    using and programming custom process schedulers, with all code required
    contained entirely in one file dedicated to such a task.  Taking into
    account the added complexity brought on by concurrency, synchronisation is
    achieved by implementing both spinlocks and mutual exclusion locks.
    
    A simple and somewhat rudimentary form of inter-process communication is
    provided, making use of the ``shared memory'' model. User interaction via
    USB keyboard is attempted and provided as a compile-time option, and makes
    use of a statically-linked library provided by Rene Stange's project
    \textit{USPi} \cite{USPi}. While not an initial requirement, the system
    provides the ability to enable the Memory Management Unit, allowing the
    programmer to define their own mapping from virtual to physical memory and
    control which memory is bufferable and cacheable.

    The project also provides a means of configuring various options at
    compile-time through sending directives via the Makefile, resulting in a
    clean and simple interface to change between various systems. At present,
    the system may be configured for running on the Raspberry Pi 1 or 2, using
    Round-Robin or First Come First Served Scheduling, and which form of
    inter-process communication to use (for which only shared memory is
    currently provided). While there is not much choice currently, this system
    is relatively simple and easy to extend as more features are developed.

    Finally, since the ability to demystify the codebase of an operating system
    is an important aspect of the project, it has been designed to be compatible
    with Doxygen \cite{Doxygen} in order to generate documentation for the
    project in a simple collection of HTML files. It provides similar
    functionality to Oracle's Javadoc \cite{Javadoc}.

    Future work will be concentrated on achieving user-interaction via USB
    keyboard and using this to implement a shell/command interpreter. A final
    important system to implement is filesystems and permanent storage, for
    which an interface to the External Mass Media Controller (EMMC) must be
    written, to enable interaction with the SD card.

\subsection{Project management}
    \subsubsection{Development methodology}
        The project has been developed in a waterfall-style approach -- this has
        been well-suited to the rigidity of system dependencies, especially in
        early versions of the operating system. For example, it was necessary to
        write the boot code and set up the C environment before writing a
        interrupt handlers before implementing process scheduling, and any
        deviation from this order would have made little sense. This
        inflexibility allowed for such core features to be planned and designed
        in advance, and meant that focus only progressed to another feature once
        they had been implemented successfully. Once these lower-level systems
        were in place, the project opened up more, particularly after having
        completed development of processes; from this point focus at any point
        could be concentrated on features such as process scheduling,
        inter-process communication, or user interaction. As such, development
        became more agile, and the decision to pursue development on certain
        features was taken by assessing their importance to the project's
        success in relation to the other possible features. Throughout the
        course of the project, goals have been set and achieved in an
        incremental manner; once deciding upon the next system to implement,
        this involved breaking it down into appropriate subtasks and completing
        each in turn. An example of this has been the development of memory
        management, first requiring the parsing of atags, followed by creating
        and maintaining a list of page metadata, and finally using these to
        write the dynamic memory allocator.

    \subsubsection{Organisation}
        From the very start of the project, the effective use of version control
        software has been vital to its success. Integrating with Git and hosting
        it remotely on Github occurred early on and has been a constant
        consideration throughout. Since testing on real hardware is so important
        to determining whether or not an embedded system truly works, the
        ability to keep track of all previous builds has been useful.  In
        particular, when features do not work, and especially if their failure
        interferes with other systems, being able to revert to the previous
        working version has helped not only in getting the project back to a
        functional state, but also in investigating and understanding precisely
        why certain attempts broke the build. Github also provides several
        useful features to track the evolution of the codebase, from detailing
        code frequency to monitoring branches. Figure \ref{fig:commits}
        highlights Github's consistent aid throughout the project, in the form
        of weekly commits over the span of the its development.

        \begin{figure}[h]
            \centering
            \includegraphics[width=.8\textwidth]{commit_graph}
            \caption{Weekly commits to the Github repository (source:
            repository's ``Insights'' page)}
            \label{fig:commits}
        \end{figure}

        Progress was initially considered in the project specification, for
        which a preliminary schedule was devised. After two months of
        development, this was then revised in the progress report.  A copy of
        this version is provided in Appendix \ref{app:timetable}, and an
        evaluation of how effective and accurate these timetabling estimates
        were is discussed in Section \ref{sec:evaluation}. In order to monitor
        progress, regular meetings were held with the project supervisor, Adam
        Chester, during which recent achievements and current issues were
        discussed, with guidance given in the case of the latter. These further
        aided in consolidating lessons learned and milestones passed, when
        otherwise it might be easy to lose track -- not vital, but helpful in
        tracking the project's progression. During Term 1, these meetings were
        held fortnightly as work on the project was less of a focus in the light
        of the higher course load regarding other modules. The frequency of
        meetings increased to weekly the following term as more time became
        available and more challenging and abstract aspects of the project
        presented themselves.

    \subsubsection{Testing \& Debugging}
        \label{sec:design_testing}
        The project was tested throughout development, and with particular
        frequency once able to boot on real hardware. This means that, once a
        subtask had been completed, the entire system was compiled and loaded
        onto hardware, with specific unit tests written each time to ensure the
        feature's correct operation. Also important was integration testing, so
        as to ensure a working implementation of one feature did not compromise
        the correct functioning of another. This was the case when enabling the
        MMU, having worked in isolation from other components, but interfering
        with the return addresses of other important functions when used in the
        wrong place or memory addresses in-use and to which it should not have
        had access -- this only became clear as a result of integration testing.

        There is little infrastructure to debug low-level software of this type,
        so much had to be done manually. Specifically, this involved inspecting
        the \code{.map} and \code{.list} files and using the Linux command-line
        utility \code{nm} \cite{nm} to display information about the generated
        executable files. Furthermore, prior to successfully sending output to a
        real screen via HDMI, there was no way to gather textual information
        about the system during execution. The only other useful way to provide
        debugging information during execution was interacting with the two
        programmable LEDs on the Pi, namely the ACT and PWR LEDs, for example
        causing them to blink at different points and in different patterns.
        Soon after successfully displaying to HDMI, it was important to develop
        a working version of \code{printf} to display debugging information in a
        flexible manner.

    \subsubsection{Legal, Ethical, and Social Issues}
        All software being used to develop is available under the GNU General
        Public License, which grants permission for commercial and private use,
        as well as modification and distribution. Most software used as a study
        resource is similarly available under the GNU General Public License,
        while several others are available under the MIT license, the main
        difference being software distributed under the former must be made
        open-source, while this is not true of the latter. Throughout the
        project's development, informal feedback has been sought from friends
        and colleagues, particularly for non-functional aspects of the software,
        such as usability and overall polish. Due to the informal nature of the
        feedback, however, ethical, social, and legal considerations need not
        apply.
